---
layout: post
title: "A Dive into Ray Tracing Performance on the Apple M1"
description: ""
category: graphics
tags: [metal, raytracing, embree]
published: true
---
{% include JB/setup %}

The Apple M1 available in the MacBook Air, MacBook Pro 13", and Mac Mini has
been the focus of a ton of benchmarking writeups and blog posts about
the new chip. The performance overall, and especially performance/watt,
that Apple has achieved with the chip is very impressive.
As a ray tracing person, what caught my eye the most was the
performance AnandTech reported in their
[CineBench benchmarks](https://www.anandtech.com/show/16252/mac-mini-apple-m1-tested/2).
These scores were 1.6x higher than I got on my old Haswell desktop and 2x
higher than my new Tiger Lake laptop!
I had also been interested in trying out the new
[ray tracing API for Metal](https://developer.apple.com/videos/play/wwdc2020/10012/)
that was announced at WWDC this year,
which bears some resemblance to the DirectX, Vulkan, and OptiX GPU ray tracing APIs.
So, I decided to pick up a Mac Mini to do some testing
on my own interactive path tracing project,
[ChameleonRT](https://github.com/Twinklebear/ChameleonRT),
and to get it running on the new Metal ray tracing API.
In this post, we'll take a look at the new Metal ray tracing
API to see how it lines up with DirectX, Vulkan, OptiX and Embree,
then we'll make some fair (and some extremely unfair) ray tracing
performance comparisons against the M1.

<!--more-->

# Overview of the Benchmark: ChameleonRT

[ChameleonRT](https://github.com/Twinklebear/ChameleonRT) is an open source
interactive path tracer that I've been working on to learn the different ray tracing APIs,
and to provide an example or starting point for myself and others working with them
in other projects.
ChameleonRT provides backends for the GPU ray tracing APIs:
[DirectX Ray Tracing](https://github.com/Twinklebear/ChameleonRT/tree/master/dxr),
[Vulkan KHR Ray Tracing](https://github.com/Twinklebear/ChameleonRT/tree/master/vulkan),
and [OptiX 7](https://github.com/Twinklebear/ChameleonRT/tree/master/optix).
Through the work discussed in this post, it also has a new
[Metal](https://github.com/Twinklebear/ChameleonRT/tree/master/metal) GPU backend.
ChameleonRT also has an [Embree backend](https://github.com/Twinklebear/ChameleonRT/tree/master/embree)
for fast multi-threaded and SIMD accelerated ray tracing on CPUs through
[Embree](https://www.embree.org/), [ISPC](https://ispc.github.io/), and [TBB](https://github.com/oneapi-src/oneTBB).
The rendering code in each backend is nearly identical and they produce almost pixel exact outputs,
with some possible small differences due to subtle differences in the ray tracing
libraries or shader languages.

ChameleonRT is different from popular ray tracing benchmark applications like
[CineBench](https://www.maxon.net/en/cinebench), [LuxMark](http://www.luxmark.info/),
and [Blender Benchmark](https://opendata.blender.org/), in that ChameleonRT is
a minimal interactive path tracer. CineBench, LuxMark, and Blender Benchmark are excellent
for getting a full picture of what performance to expect from a production film
renderer, as they are production renderers. However, there's a lot more going
on in a production renderer than just ray tracing to support the kind of complex
geometries, materials, and effects used in film; and the large code
bases can be challenging to quickly port to a new architecture or API.
ChameleonRT is the exact opposite, supporting just one geometry type,
triangle meshes, and one material type, the Disney BRDF.
The rest of the code is similarly written to achieve interactive path tracing performance,
though I have tried to balance this with how complex the code is to read.
For example, the renderers use iterative ray tracing instead of recursion,
support only a simple sampling strategy, and don't support alpha cut-out effects.
The use of iterative ray tracing is valuable on both the CPU and GPU, but is
especially important on the GPU, as the
overhead of recursive ray tracing calls in the pipeline can have a significant performance impact.
Similarly, ignoring alpha cut-out effects allows the GPU renderers
to skip using an any hit shader (and the Embree on to skip needing an intersection
filter). The any hit shader (or intersection filter) would be called during
BVH traversal after a candidate intersection with a triangle is found.
In the case that the BVH traversal is hardware accelerated, this ends up
producing a lot amount of back and
forth between the fixed function traversal hardware and the shader cores to run the any hit
shader during traversal, limiting the hardware's performance.

> What's a path tracer? Path tracing is a technique in computer graphics for
> rendering photo-realistic images by simulating the light transport in
> the scene. It is a Monte Carlo technique, meaning that it randomly samples
> light paths emitted from lights in the scene that reach the camera
> by bouncing off objects in the scene. This is done by tracing the paths in reverse,
> starting from the camera and tracing the path back through the scene.
> A large number of light paths need to be sampled to produce a noise-free
> image. Path tracing is not restricted to photo-realism, and is the
> core rendering algorithm used in major film renderers, such as: Pixar's Renderman,
> Disney's Hyperion, Autodesk's Arnold, and Weta's Manuka.
> See [Wikipedia](https://en.wikipedia.org/wiki/Path_tracing) for more.

# Experience with GPU Ray Tracing with Metal

The new ray tracing API in Metal will be familiar to those who've used inline ray
tracing in DirectX or Vulkan. For a good introduction to Metal's API, check out the [Discover ray tracing
with Metal](https://developer.apple.com/videos/play/wwdc2020/10012/) video from WWDC 2020,
and the [accompanying sample](https://developer.apple.com/documentation/metal/accelerating_ray_tracing_using_metal?language=objc).
Inline ray tracing allows applications to make ray tracing calls in any shader stage,
e.g., fragment/pixel shaders, vertex shaders, compute shaders, etc.
Inline ray tracing allows ray tracing effects, for example accurate reflections and shadows,
to be integrated into the regular rasterization pipeline.
Inline ray tracing can also be used from a compute shader to implement a standalone
path tracing based renderer. ChameleonRT is a standalone path tracer, and takes
the compute shader approach for Metal.

At a high-level, ray tracing in Metal proceeds as follows: you upload your
geometry data, build bottom-level primitive acceleration structures over them, then create instances
referencing those acceleration structures and build a top-level acceleration structure over
the instances.
To render the scene you dispatch a compute shader and trace rays against the top-level
acceleration structure to get back intersection results. The intersection results provide
you with the intersected primitive and geometry IDs, and if using instancing, the instance ID.
Your shader can then look up the geometry data for the object that was hit and shade it,
after which it can continue tracing the path.

At this time Metal only supports inline ray tracing, in contrast to DirectX and Vulkan, which
also provide support for ray tracing pipelines. Ray tracing pipelines are used
to implement standalone ray tracing renderers, and is the approach ChameleonRT
uses in its DirectX and Vulkan backends.
OptiX only supports ray tracing pipelines.
Ray tracing pipelines require the creation of a Shader Binding Table to
provide the API with a table of functions to call when specific objects
in the scene are intersected. The SBT can be difficult to setup and debug,
and is a common point of difficulty for developers learning these APIs.
For more information about the SBT, check out my post
["The RTX Shader Binding Table Three Ways"]({% post_url 2019-11-20-the-sbt-three-ways %}).
However, the potential benefit of the SBT is that the GPU can reorder or group function
calls to reduce thread divergence. With inline ray tracing, the developer
must do this themselves, or do without
(check out another video from [WWDC20](https://developer.apple.com/videos/play/wwdc2020/10013/)
for information here).
Right now, ChameleonRT does not do any reordering to reduce divergence.

Those familiar with Metal may know of the previous
[Metal Performance Shaders ray intersector](https://developer.apple.com/documentation/metalperformanceshaders/metal_for_accelerating_ray_tracing?language=objc).
The new support for inline ray tracing improves on this by allowing the renderer
to move entirely to the GPU. The previous ray intersector worked by taking
batches of rays, finding intersections in the scene, and writing these results
back out to memory. Multiple compute shaders would need to be dispatched to
trace the primary rays and create shadow and secondary rays, then trace the shadow rays
and continue the secondary rays while filtering out paths that terminated.
This requires significantly more memory traffic and compute dispatches, introducing overhead
to the renderer. Such an approach is also not well suited to augmenting traditional
rasterization pipelines with ray tracing effects.
Approaches based on tracing and sorting rays and intersection information to extract
coherence are valuable for complex film renderers, and can be implemented efficiently using inline
ray tracing as well.
For example, [Disney's Hyperion renderer](https://www.yiningkarlli.com/projects/hyperiondesign.html)
uses sorting and batching extensively to
extract coherent workloads from an otherwise incoherent and divergent distribution of rays.
There's also an excellent higher-level [video](https://youtu.be/frLwRLS_ZR0) explaining how this
works.

The Metal ray tracing API is quite nice to work with.
It bears a lot of similarity to the other ray tracing APIs, but has been streamlined
to be easier to use.
For example, compare the code required to build and compact a BVH in
[DirectX](https://github.com/Twinklebear/ChameleonRT/blob/master/dxr/dxr_utils.cpp#L877-L977)
or [Vulkan](https://github.com/Twinklebear/ChameleonRT/blob/master/vulkan/vulkanrt_utils.cpp#L46-L214)
with [Metal](https://github.com/Twinklebear/ChameleonRT/blob/master/metal/metalrt_utils.mm#L318-L396).
OptiX's API provides a similar simplification, here's the
[BVH build in OptiX](https://github.com/Twinklebear/ChameleonRT/blob/master/optix/optix_utils.cpp#L183-L244)
for reference.
It's also nice to have templates and C++ style functionality in the shader language,
a feature Metal shares with OptiX, which uses CUDA for the device side code.

This simplicity also has some drawbacks. For example, while in DirectX, Vulkan, and OptiX
you have control over where the acceleration structure memory is allocated,
Metal makes this allocation for you. As a result, you cannot allocate the acceleration
structures on a `MTLHeap`, and so to make sure they're available for your rendering
pipeline, you must individually mark them as used in a loop instead of a single `useHeap` call.

{% highlight objc %}
// Use our top level acceleration structure
[command_encoder setAccelerationStructure:bvh->bvh atBufferIndex:1];
// Also mark all mesh acceleration structures used, as they're indirectly
// referenced by the top level one
for (auto &mesh : bvh->meshes) {
    [command_encoder useResource:mesh->bvh usage:MTLResourceUsageRead];
}
{% endhighlight %}

This can add some overhead if you have a lot of bottom level BVHs, as can be the
case in scenes with many instances.
It'd be nice to be able to allocate the acceleration structures on a heap, and replace this loop
with a single `[command_encoder useHeap:data_heap->heap];`

The API is also simplified significantly by not including ray tracing pipelines and
only requiring a Shader Binding Table-esque
structure when implementing custom geometries or other operations that need
to happen during traversal (e.g., alpha cut-outs).
Code for managing the SBT setup in DirectX, Vulkan, and OptiX, makes up a significant
portion of my helper code in each backend, and it's nice to skip this
in the Metal backend, which doesn't implement custom geometry or alpha cut-out textures.
However, in an SBT model the GPU could group or reorder function calls to reduce divergence,
but this is less possible with inline ray tracing where this information isn't available
to the driver.
In the end you may find yourself implementing something a bit like the SBT
but a bit simpler to look up the right data for the primtives/meshes/instances
in your scene in argument buffers, as I've done in ChameleonRT.
Overall these are relatively small issues though.

# Fast CPU Ray Tracing with Intel Libraries

What caught my interest the most about AnandTech's CineBench
results is that CineBench actually uses [Embree](https://www.embree.org/)
for ray tracing, which is a library developed by Intel!
Embree is a CPU ray tracing library that provides optimized
acceleration structure traversal and primitive intersection
methods, similar to the GPU ray tracing APIs. Embree was
initially released in 2011 and has found widespread adoption
across film, scientific visualization, and other domains.


# Benchmarks

<div class="col-12 row mb-2">
    <div class="col-6">
        <a href="https://i.imgur.com/uiIgXdJ.png">
        <img class="img-fluid" src="https://i.imgur.com/uiIgXdJ.png"/>
        </a>
    </div>
    <div class="col-6">
        <a href="https://i.imgur.com/f8H3pAc.png">
        <img class="img-fluid" src="https://i.imgur.com/f8H3pAc.png"/>
        </a>
    </div>
    <p>
    <b>Figure 1:</b> <i>The test scenes used in the benchmarks.
    Sponza (left) has 262K triangles, San Miguel (right) has 9.96M</i>
    </p>
</div>

## Fair Comparisons

## Extremely Unfair Comparisons

i9-9920x, rtx 2070

# Wrap Up

I've been using the Mac Mini as my daily computer for the past 2 weeks or so,
and have been really happy with both the performance and the silence.
There's really something to be said for a practically silent computer
compared to my louder desktop.

I want hardware BVH traversal and triangle intersection, and 8-wide SIMD.

